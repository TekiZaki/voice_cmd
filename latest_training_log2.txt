PS C:\Dzaki\Tugas\UMB\Sem 7\Pengantar Deep Learning\voice_cmd> py model.py
2026-01-23 18:12:06.219681: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-23 18:12:12.086035: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
============================================================
ğŸ¤ VOICE COMMAND MODEL TRAINER (V2 - ROBUST)
============================================================
ğŸ“‚ Detected classes: ['atas', 'backspace', 'back_home', 'bawah', 'buka_mc-edge', 'buka_note_win_10', 'buka_wa', 'close', 'copy', 'force close', 'hello_voicecmd', 'kanan', 'kiri', 'new_tab', 'paste', 'percepat', 'perlambat', 'refresh', 'searching', 'select_all', 'sleep_cmd', 'tab', 'tab_down', 'tab_up']
   Processing atas: 40 raw samples...
   Processing backspace: 60 raw samples...
   Processing back_home: 60 raw samples...
   Processing bawah: 40 raw samples...
   Processing buka_mc-edge: 60 raw samples...
   Processing buka_note_win_10: 50 raw samples...
   Processing buka_wa: 50 raw samples...
   Processing close: 50 raw samples...
   Processing copy: 40 raw samples...
   Processing force close: 50 raw samples...
   Processing hello_voicecmd: 60 raw samples...
   Processing kanan: 40 raw samples...
   Processing kiri: 40 raw samples...
   Processing new_tab: 40 raw samples...
   Processing paste: 40 raw samples...
   Processing percepat: 40 raw samples...
   Processing perlambat: 40 raw samples...
   Processing refresh: 40 raw samples...
   Processing searching: 40 raw samples...
   Processing select_all: 40 raw samples...
   Processing sleep_cmd: 60 raw samples...
   Processing tab: 30 raw samples...
   Processing tab_down: 70 raw samples...
   Processing tab_up: 70 raw samples...
ğŸ”Š Generating SYNTHETIC background noise (fallback)...

âœ… Total Training Samples (Augmented): 4463
ğŸ“ Classes (25): ['atas' 'back_home' 'background' 'backspace' 'bawah' 'buka_mc-edge'
 'buka_note_win_10' 'buka_wa' 'close' 'copy' 'force close'
 'hello_voicecmd' 'kanan' 'kiri' 'new_tab' 'paste' 'percepat' 'perlambat'
 'refresh' 'searching' 'select_all' 'sleep_cmd' 'tab' 'tab_down' 'tab_up']

ğŸ—ï¸  Model Input Shape: (87, 120)
2026-01-23 18:13:13.243978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ reshape (Reshape)                    â”‚ (None, 87, 120, 1)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)                      â”‚ (None, 87, 120, 16)         â”‚             160 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation (Activation)              â”‚ (None, 87, 120, 16)         â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization                  â”‚ (None, 87, 120, 16)         â”‚              64 â”‚
â”‚ (BatchNormalization)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)         â”‚ (None, 43, 60, 16)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 43, 60, 16)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)                    â”‚ (None, 43, 60, 32)          â”‚           4,640 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1 (Activation)            â”‚ (None, 43, 60, 32)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1                â”‚ (None, 43, 60, 32)          â”‚             128 â”‚
â”‚ (BatchNormalization)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)       â”‚ (None, 21, 30, 32)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)                  â”‚ (None, 21, 30, 32)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)                    â”‚ (None, 21, 30, 64)          â”‚          18,496 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2 (Activation)            â”‚ (None, 21, 30, 64)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_2                â”‚ (None, 21, 30, 64)          â”‚             256 â”‚
â”‚ (BatchNormalization)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2 (MaxPooling2D)       â”‚ (None, 10, 15, 64)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)                  â”‚ (None, 10, 15, 64)          â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)                    â”‚ (None, 9600)                â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 64)                  â”‚         614,464 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_3                â”‚ (None, 64)                  â”‚             256 â”‚
â”‚ (BatchNormalization)                 â”‚                             â”‚                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 (Dropout)                  â”‚ (None, 64)                  â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 25)                  â”‚           1,625 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 640,089 (2.44 MB)
 Trainable params: 639,737 (2.44 MB)
 Non-trainable params: 352 (1.38 KB)

ğŸš€ Starting Training...
Epoch 1/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 184ms/step - accuracy: 0.1350 - loss: 3.6472 - val_accuracy: 0.2800 - val_loss: 2.7108 - learning_rate: 0.0010
Epoch 2/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.4228 - loss: 2.3059 - val_accuracy: 0.4882 - val_loss: 2.2216 - learning_rate: 0.0010
Epoch 3/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 173ms/step - accuracy: 0.6176 - loss: 1.7282 - val_accuracy: 0.7660 - val_loss: 1.4260 - learning_rate: 0.0010
Epoch 4/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.7081 - loss: 1.3943 - val_accuracy: 0.8052 - val_loss: 1.1058 - learning_rate: 0.0010
Epoch 5/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.7714 - loss: 1.1501 - val_accuracy: 0.8791 - val_loss: 0.8016 - learning_rate: 0.0010
Epoch 6/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 174ms/step - accuracy: 0.8202 - loss: 0.9748 - val_accuracy: 0.8891 - val_loss: 0.7135 - learning_rate: 0.0010
Epoch 7/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 172ms/step - accuracy: 0.8499 - loss: 0.8541 - val_accuracy: 0.5745 - val_loss: 1.9742 - learning_rate: 0.0010
Epoch 8/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.8747 - loss: 0.7544 - val_accuracy: 0.9239 - val_loss: 0.5780 - learning_rate: 0.0010
Epoch 9/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 182ms/step - accuracy: 0.8870 - loss: 0.6915 - val_accuracy: 0.9194 - val_loss: 0.5711 - learning_rate: 0.0010
Epoch 10/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.8975 - loss: 0.6693 - val_accuracy: 0.9518 - val_loss: 0.4921 - learning_rate: 0.0010
Epoch 11/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.9288 - loss: 0.5822 - val_accuracy: 0.9530 - val_loss: 0.4854 - learning_rate: 0.0010
Epoch 12/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9133 - loss: 0.6013 - val_accuracy: 0.9541 - val_loss: 0.4697 - learning_rate: 0.0010
Epoch 13/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 180ms/step - accuracy: 0.9312 - loss: 0.5518 - val_accuracy: 0.9440 - val_loss: 0.4931 - learning_rate: 0.0010
Epoch 14/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9337 - loss: 0.5307 - val_accuracy: 0.9630 - val_loss: 0.4492 - learning_rate: 0.0010
Epoch 15/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 173ms/step - accuracy: 0.9466 - loss: 0.5007 - val_accuracy: 0.9574 - val_loss: 0.4621 - learning_rate: 0.0010
Epoch 16/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9551 - loss: 0.4657 - val_accuracy: 0.9653 - val_loss: 0.4263 - learning_rate: 0.0010
Epoch 17/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9537 - loss: 0.4629 - val_accuracy: 0.9597 - val_loss: 0.4303 - learning_rate: 0.0010
Epoch 18/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9586 - loss: 0.4326 - val_accuracy: 0.9731 - val_loss: 0.4001 - learning_rate: 0.0010
Epoch 19/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 181ms/step - accuracy: 0.9588 - loss: 0.4521 - val_accuracy: 0.9686 - val_loss: 0.4219 - learning_rate: 0.0010
Epoch 20/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9536 - loss: 0.4536 - val_accuracy: 0.9586 - val_loss: 0.4266 - learning_rate: 0.0010
Epoch 21/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9573 - loss: 0.4439 - val_accuracy: 0.9552 - val_loss: 0.4680 - learning_rate: 0.0010
Epoch 22/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 174ms/step - accuracy: 0.9582 - loss: 0.4480 - val_accuracy: 0.9630 - val_loss: 0.4202 - learning_rate: 0.0010
Epoch 23/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 170ms/step - accuracy: 0.9595 - loss: 0.4439
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9595 - loss: 0.4439 - val_accuracy: 0.9709 - val_loss: 0.4069 - learning_rate: 0.0010
Epoch 24/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9734 - loss: 0.4160 - val_accuracy: 0.9686 - val_loss: 0.3925 - learning_rate: 5.0000e-04
Epoch 25/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 174ms/step - accuracy: 0.9761 - loss: 0.3810 - val_accuracy: 0.9720 - val_loss: 0.3951 - learning_rate: 5.0000e-04
Epoch 26/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9791 - loss: 0.3632 - val_accuracy: 0.9765 - val_loss: 0.3513 - learning_rate: 5.0000e-04
Epoch 27/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 180ms/step - accuracy: 0.9772 - loss: 0.3474 - val_accuracy: 0.9776 - val_loss: 0.3401 - learning_rate: 5.0000e-04
Epoch 28/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9819 - loss: 0.3228 - val_accuracy: 0.9754 - val_loss: 0.3290 - learning_rate: 5.0000e-04
Epoch 29/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9777 - loss: 0.3211 - val_accuracy: 0.9787 - val_loss: 0.3322 - learning_rate: 5.0000e-04
Epoch 30/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.9887 - loss: 0.2995 - val_accuracy: 0.9810 - val_loss: 0.3133 - learning_rate: 5.0000e-04
Epoch 31/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9808 - loss: 0.3125 - val_accuracy: 0.9821 - val_loss: 0.2957 - learning_rate: 5.0000e-04
Epoch 32/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 181ms/step - accuracy: 0.9813 - loss: 0.3028 - val_accuracy: 0.9798 - val_loss: 0.2986 - learning_rate: 5.0000e-04
Epoch 33/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 180ms/step - accuracy: 0.9783 - loss: 0.3075 - val_accuracy: 0.9843 - val_loss: 0.2943 - learning_rate: 5.0000e-04
Epoch 34/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.9798 - loss: 0.3011 - val_accuracy: 0.9754 - val_loss: 0.3101 - learning_rate: 5.0000e-04
Epoch 35/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9785 - loss: 0.2897 - val_accuracy: 0.9765 - val_loss: 0.3107 - learning_rate: 5.0000e-04
Epoch 36/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 180ms/step - accuracy: 0.9824 - loss: 0.2780 - val_accuracy: 0.9810 - val_loss: 0.2983 - learning_rate: 5.0000e-04
Epoch 37/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.9826 - loss: 0.2815 - val_accuracy: 0.9810 - val_loss: 0.2855 - learning_rate: 5.0000e-04
Epoch 38/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9854 - loss: 0.2686 - val_accuracy: 0.9821 - val_loss: 0.2909 - learning_rate: 5.0000e-04
Epoch 39/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 174ms/step - accuracy: 0.9751 - loss: 0.2813 - val_accuracy: 0.9810 - val_loss: 0.2779 - learning_rate: 5.0000e-04
Epoch 40/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9789 - loss: 0.2837 - val_accuracy: 0.9821 - val_loss: 0.3037 - learning_rate: 5.0000e-04
Epoch 41/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9842 - loss: 0.2789 - val_accuracy: 0.9832 - val_loss: 0.2789 - learning_rate: 5.0000e-04
Epoch 42/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 173ms/step - accuracy: 0.9866 - loss: 0.2646 - val_accuracy: 0.9776 - val_loss: 0.2815 - learning_rate: 5.0000e-04
Epoch 43/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9846 - loss: 0.2566 - val_accuracy: 0.9832 - val_loss: 0.2731 - learning_rate: 5.0000e-04
Epoch 44/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9845 - loss: 0.2678 - val_accuracy: 0.9776 - val_loss: 0.2836 - learning_rate: 5.0000e-04
Epoch 45/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9886 - loss: 0.2576 - val_accuracy: 0.9798 - val_loss: 0.2770 - learning_rate: 5.0000e-04
Epoch 46/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9842 - loss: 0.2522 - val_accuracy: 0.9843 - val_loss: 0.2823 - learning_rate: 5.0000e-04
Epoch 47/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 173ms/step - accuracy: 0.9832 - loss: 0.2599 - val_accuracy: 0.9742 - val_loss: 0.2988 - learning_rate: 5.0000e-04
Epoch 48/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 168ms/step - accuracy: 0.9814 - loss: 0.2698
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 175ms/step - accuracy: 0.9814 - loss: 0.2698 - val_accuracy: 0.9832 - val_loss: 0.2877 - learning_rate: 5.0000e-04
Epoch 49/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 171ms/step - accuracy: 0.9844 - loss: 0.2687 - val_accuracy: 0.9843 - val_loss: 0.2710 - learning_rate: 2.5000e-04
Epoch 50/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9844 - loss: 0.2572 - val_accuracy: 0.9843 - val_loss: 0.2737 - learning_rate: 2.5000e-04
Epoch 51/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 171ms/step - accuracy: 0.9906 - loss: 0.2284 - val_accuracy: 0.9843 - val_loss: 0.2565 - learning_rate: 2.5000e-04
Epoch 52/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9918 - loss: 0.2226 - val_accuracy: 0.9854 - val_loss: 0.2576 - learning_rate: 2.5000e-04
Epoch 53/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9922 - loss: 0.2137 - val_accuracy: 0.9854 - val_loss: 0.2468 - learning_rate: 2.5000e-04
Epoch 54/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9929 - loss: 0.2133 - val_accuracy: 0.9877 - val_loss: 0.2386 - learning_rate: 2.5000e-04
Epoch 55/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9904 - loss: 0.2125 - val_accuracy: 0.9832 - val_loss: 0.2420 - learning_rate: 2.5000e-04
Epoch 56/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 176ms/step - accuracy: 0.9911 - loss: 0.2066 - val_accuracy: 0.9877 - val_loss: 0.2317 - learning_rate: 2.5000e-04
Epoch 57/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 180ms/step - accuracy: 0.9935 - loss: 0.1934 - val_accuracy: 0.9877 - val_loss: 0.2262 - learning_rate: 2.5000e-04
Epoch 58/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9911 - loss: 0.1929 - val_accuracy: 0.9843 - val_loss: 0.2265 - learning_rate: 2.5000e-04
Epoch 59/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9925 - loss: 0.1909 - val_accuracy: 0.9866 - val_loss: 0.2210 - learning_rate: 2.5000e-04
Epoch 60/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9950 - loss: 0.1885 - val_accuracy: 0.9843 - val_loss: 0.2291 - learning_rate: 2.5000e-04
Epoch 61/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9942 - loss: 0.1788 - val_accuracy: 0.9854 - val_loss: 0.2205 - learning_rate: 2.5000e-04
Epoch 62/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 174ms/step - accuracy: 0.9932 - loss: 0.1747 - val_accuracy: 0.9877 - val_loss: 0.2156 - learning_rate: 2.5000e-04
Epoch 63/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9913 - loss: 0.1801 - val_accuracy: 0.9866 - val_loss: 0.2092 - learning_rate: 2.5000e-04
Epoch 64/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9891 - loss: 0.1803 - val_accuracy: 0.9888 - val_loss: 0.2064 - learning_rate: 2.5000e-04
Epoch 65/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9930 - loss: 0.1699 - val_accuracy: 0.9899 - val_loss: 0.2031 - learning_rate: 2.5000e-04
Epoch 66/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 178ms/step - accuracy: 0.9939 - loss: 0.1672 - val_accuracy: 0.9810 - val_loss: 0.2259 - learning_rate: 2.5000e-04
Epoch 67/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 179ms/step - accuracy: 0.9888 - loss: 0.1701 - val_accuracy: 0.9866 - val_loss: 0.1997 - learning_rate: 2.5000e-04
Epoch 68/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 177ms/step - accuracy: 0.9939 - loss: 0.1630 - val_accuracy: 0.9877 - val_loss: 0.2054 - learning_rate: 2.5000e-04
Epoch 69/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19s 174ms/step - accuracy: 0.9919 - loss: 0.1651 - val_accuracy: 0.9686 - val_loss: 0.2922 - learning_rate: 2.5000e-04
Epoch 70/70
112/112 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20s 181ms/step - accuracy: 0.9950 - loss: 0.1550 - val_accuracy: 0.9888 - val_loss: 0.1897 - learning_rate: 2.5000e-04
Restoring model weights from the end of the best epoch: 70.
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.

âœ… Training Complete & Model Saved!
28/28 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 27ms/step - accuracy: 0.9907 - loss: 0.1828
ğŸ“Š Final Test Accuracy: 98.88%